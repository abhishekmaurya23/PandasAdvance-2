{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b0a9d9-9bfa-4d75-bd69-325f36624109",
   "metadata": {},
   "source": [
    "Ans 1\n",
    "To print the data present in the second row of a DataFrame `df`, you can use the `.iloc` indexer with the row index. Here's an example code snippet:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'Name': ['John', 'Emily', 'Mark'],\n",
    "        'Age': [25, 32, 28],\n",
    "        'City': ['New York', 'London', 'Paris']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print data in the second row\n",
    "second_row = df.iloc[1]\n",
    "print(second_row)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Name       Emily\n",
    "Age           32\n",
    "City      London\n",
    "Name: 1, dtype: object\n",
    "```\n",
    "\n",
    "In this example, the DataFrame `df` has three rows. Using `.iloc[1]` retrieves the data in the second row of the DataFrame. The output displays the values in the second row along with their corresponding column names.\n",
    "\n",
    "You can access specific elements of the second row by indexing the `second_row` object. For example, `second_row['Name']` will give you the name in the second row.\n",
    "\n",
    "Note that row indexing starts from 0, so the second row has an index of 1.\n",
    "\n",
    "I hope this helps! Let me know if you have any further questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de3a5f-4835-46e9-b703-0eb663909a1c",
   "metadata": {},
   "source": [
    "Ans 2\n",
    "In Pandas, both `loc` and `iloc` are used to access data in a DataFrame, but they have different approaches for indexing and retrieving data. Here's the difference between the `loc` and `iloc` functions in a DataFrame:\n",
    "\n",
    "**`loc`**: The `loc` function is primarily label-based. It allows you to access data using labels or boolean arrays that specify row and column labels. When using `loc`, you provide the explicit labels of rows and columns to retrieve data. The syntax for `loc` is `df.loc[row_label, column_label]`. Here, `row_label` can be a single label, a list of labels, or a boolean array, and `column_label` can be a single label, a list of labels, or a boolean array.\n",
    "\n",
    "Example usage of `loc`:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Access a single element using label-based indexing\n",
    "value = df.loc['Y', 'B']\n",
    "\n",
    "# Access a specific row using label-based indexing\n",
    "row = df.loc['X']\n",
    "\n",
    "# Access multiple rows and columns using label-based indexing\n",
    "subset = df.loc[['X', 'Z'], ['A', 'C']]\n",
    "\n",
    "# Access rows based on a condition using label-based indexing\n",
    "filtered_rows = df.loc[df['A'] > 1]\n",
    "```\n",
    "\n",
    "**`iloc`**: The `iloc` function is primarily integer-based. It allows you to access data using integer-based indexing, irrespective of the row and column labels. When using `iloc`, you provide the integer-based positions of rows and columns to retrieve data. The syntax for `iloc` is `df.iloc[row_position, column_position]`. Here, `row_position` can be a single position, a list of positions, or a boolean array, and `column_position` can be a single position, a list of positions, or a boolean array.\n",
    "\n",
    "Example usage of `iloc`:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "\n",
    "# Access a single element using integer-based indexing\n",
    "value = df.iloc[1, 2]\n",
    "\n",
    "# Access a specific row using integer-based indexing\n",
    "row = df.iloc[0]\n",
    "\n",
    "# Access multiple rows and columns using integer-based indexing\n",
    "subset = df.iloc[[0, 2], [0, 2]]\n",
    "\n",
    "# Access rows based on a condition using integer-based indexing\n",
    "filtered_rows = df.iloc[df['A'] > 1]\n",
    "```\n",
    "\n",
    "In summary, the main difference between `loc` and `iloc` is that `loc` uses label-based indexing, while `iloc` uses integer-based indexing. `loc` provides more flexibility when accessing data based on labels or boolean conditions, while `iloc` is more focused on accessing data using integer positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdbb23-5204-421a-94ad-c13e6fd19edc",
   "metadata": {},
   "source": [
    "Ans 3\n",
    "To reindex the given DataFrame `df1` using the provided `reindex` variable and store it in the variable `new_df`, you can use the `reindex()` function. Here's the code snippet to accomplish that:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Reindexing the DataFrame\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df1.reindex(reindex)\n",
    "\n",
    "# Print the output for new_df.loc[2] and new_df.iloc[2]\n",
    "print(\"new_df.loc[2]:\")\n",
    "print(new_df.loc[2])\n",
    "print(\"new_df.iloc[2]:\")\n",
    "print(new_df.iloc[2])\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "new_df.loc[2]:\n",
    "column_1    0.622550\n",
    "column_2    0.321618\n",
    "column_3    0.203379\n",
    "column_4    0.770235\n",
    "column_5    0.641055\n",
    "column_6    0.526576\n",
    "Name: 2, dtype: float64\n",
    "new_df.iloc[2]:\n",
    "column_1    0.842623\n",
    "column_2    0.248277\n",
    "column_3    0.203694\n",
    "column_4    0.234729\n",
    "column_5    0.120826\n",
    "column_6    0.586194\n",
    "Name: 1, dtype: float64\n",
    "```\n",
    "\n",
    "In this code, we first create the DataFrame `df1` with random data using `np.random.rand()`, specifying the columns and indices. Then, we define the `reindex` variable as `[3, 0, 1, 2]`.\n",
    "\n",
    "Next, we reindex `df1` using the `reindex()` function, which returns a new DataFrame `new_df` with the specified row order. We then print the output for `new_df.loc[2]` and `new_df.iloc[2]`.\n",
    "\n",
    "Observations:\n",
    "- `new_df.loc[2]` returns the row with index label 2 from `new_df`. The output includes the values of the row along with their respective column names.\n",
    "- `new_df.iloc[2]` returns the third row (index position 2) from `new_df`. The output includes the values of the row but without the column names.\n",
    "\n",
    "The key difference is that `loc` uses the index labels, while `iloc` uses the integer-based index positions. So, while both `loc` and `iloc` provide access to specific rows or columns, `loc` uses the index labels for selection, and `iloc` uses integer-based positions.\n",
    "\n",
    "I hope this clarifies the difference between `loc` and `iloc` when applied to the reindexed DataFrame `new_df`. Let me know if you have any further questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229af72-b6c3-4881-b2c0-b20e35571da3",
   "metadata": {},
   "source": [
    "Ans 4\n",
    "Sure! Here's the code to calculate the mean of each column and the standard deviation of the 'column_2' in the DataFrame `df1`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df1 is your DataFrame\n",
    "df1 = pd.DataFrame({'column_1': [1, 2, 3, 4, 5],\n",
    "                    'column_2': [6, 7, 8, 9, 10],\n",
    "                    'column_3': [11, 12, 13, 14, 15]})\n",
    "\n",
    "# Calculate the mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "print()\n",
    "\n",
    "# Calculate the standard deviation of column 'column_2'\n",
    "column_2_std = df1['column_2'].std()\n",
    "print(\"Standard deviation of column 'column_2':\", column_2_std)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Mean of each column:\n",
    "column_1     3.0\n",
    "column_2     8.0\n",
    "column_3    13.0\n",
    "dtype: float64\n",
    "\n",
    "Standard deviation of column 'column_2': 1.5811388300841898\n",
    "```\n",
    "\n",
    "In the above code, we assume that `df1` is your DataFrame with columns 'column_1', 'column_2', and 'column_3'.\n",
    "\n",
    "To calculate the mean of each column, we use the `mean()` function on the DataFrame `df1`, which returns a Series containing the means of each column.\n",
    "\n",
    "To calculate the standard deviation of 'column_2', we use the `std()` function on the 'column_2' column of `df1`, which returns the standard deviation value.\n",
    "\n",
    "Finally, we print the mean of each column and the standard deviation of 'column_2'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6215882-6c42-41a6-9cd2-a0dd53288ac7",
   "metadata": {},
   "source": [
    "Ans 5\n",
    "To replace the data present in the second row of the column 'column_2' in DataFrame `df1` with a string variable and calculate the mean of 'column_2', you can use the `loc` indexer to access the specific row and column. However, replacing numeric values with a string will result in an error when calculating the mean since the column needs to contain numeric data.\n",
    "\n",
    "Here's an example code snippet that demonstrates the scenario:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replacing the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'string data'\n",
    "\n",
    "# Calculating the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "```\n",
    "\n",
    "When executing this code, you will encounter a `TypeError` when calculating the mean because the 'column_2' column contains a mixture of numeric and string data. The mean calculation requires numeric data, but a string is not a valid input for calculating the mean.\n",
    "\n",
    "If you want to replace the data in the second row of 'column_2' with a string and calculate the mean, you need to ensure that the column only contains numeric values. Otherwise, you can convert the column to a suitable data type before calculating the mean.\n",
    "\n",
    "Here's an updated example where we convert 'column_2' to numeric values using `pd.to_numeric()` before replacing the data and calculating the mean:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Converting 'column_2' to numeric data type\n",
    "df1['column_2'] = pd.to_numeric(df1['column_2'], errors='coerce')\n",
    "\n",
    "# Replacing the data in the second row of 'column_2' with a string\n",
    "df1.loc[2, 'column_2'] = 'string data'\n",
    "\n",
    "# Calculating the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "```\n",
    "\n",
    "By using `pd.to_numeric()` with `errors='coerce'`, we convert 'column_2' to numeric values and handle any non-numeric entries by converting them to NaN. This allows us to replace the data in the second row with a string and proceed to calculate the mean of 'column_2'.\n",
    "\n",
    "Please note that replacing numeric data with a string and calculating the mean is an unusual scenario. Typically, mean calculations are performed on numeric data types to provide meaningful results.\n",
    "\n",
    "Let me know if you have any further questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb40aeb-7d7f-47cc-bfdd-4039f1a927fc",
   "metadata": {},
   "source": [
    "Ans 6\n",
    "In Pandas, a window function (also known as a rolling or rolling window function) is a powerful tool for performing calculations on a sliding window of data points within a DataFrame. It allows you to compute aggregate functions (such as mean, sum, min, max) over a specified window size, which can be defined by a number of rows or a time-based interval.\n",
    "\n",
    "Window functions operate on a specific column or multiple columns and provide a way to analyze data in a rolling or moving fashion, enabling you to capture trends, patterns, or statistics over a particular window of observations.\n",
    "\n",
    "Types of Window Functions in Pandas:\n",
    "1. **Rolling Window Functions**: Rolling window functions compute the aggregate values over a fixed-size rolling window. The window size can be defined by a number of rows. Common rolling window functions include:\n",
    "   - `rolling().mean()`: Calculates the rolling mean over the window.\n",
    "   - `rolling().sum()`: Computes the rolling sum over the window.\n",
    "   - `rolling().min()`, `rolling().max()`: Computes the rolling minimum and maximum values over the window, respectively.\n",
    "   - `rolling().std()`, `rolling().var()`: Calculates the rolling standard deviation and variance over the window, respectively.\n",
    "\n",
    "2. **Expanding Window Functions**: Expanding window functions calculate aggregate values that continually expand as new observations are added to the window. In other words, the window grows over time. Common expanding window functions include:\n",
    "   - `expanding().mean()`: Computes the expanding mean over all preceding observations.\n",
    "   - `expanding().sum()`: Calculates the expanding sum over all preceding observations.\n",
    "   - `expanding().min()`, `expanding().max()`: Calculates the expanding minimum and maximum values over all preceding observations, respectively.\n",
    "   - `expanding().std()`, `expanding().var()`: Calculates the expanding standard deviation and variance over all preceding observations, respectively.\n",
    "\n",
    "3. **Exponentially Weighted Window Functions**: Exponentially weighted window functions compute aggregate values with exponentially decreasing weights as the observations get further from the current data point. These functions assign higher weights to recent observations. Common exponentially weighted window functions include:\n",
    "   - `ewm().mean()`: Computes the exponentially weighted moving average.\n",
    "   - `ewm().sum()`: Calculates the exponentially weighted moving sum.\n",
    "   - `ewm().std()`, `ewm().var()`: Calculates the exponentially weighted moving standard deviation and variance, respectively.\n",
    "\n",
    "These window functions can be applied to a DataFrame column or a subset of columns using methods like `rolling()`, `expanding()`, and `ewm()` in combination with other aggregate functions available in Pandas.\n",
    "\n",
    "By utilizing window functions, you can gain insights into trends, patterns, or summary statistics over specific windows of data, making them invaluable for time series analysis, signal processing, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a590e1-de06-4aa9-a5a1-cc39a25543a0",
   "metadata": {},
   "source": [
    "Ans 7 \n",
    "To print the current month and year, you can utilize the `datetime` module from the Python standard library along with the `pandas` library. Here's an example code snippet that demonstrates this:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_date = datetime.now()\n",
    "\n",
    "# Extract the month and year from the current date\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# Print the current month and year\n",
    "print(\"Current Month:\", current_month)\n",
    "print(\"Current Year:\", current_year)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Current Month: 7\n",
    "Current Year: 2023\n",
    "```\n",
    "\n",
    "In this code, `datetime.now()` returns the current date and time. Then, the `month` attribute is used to extract the current month, and the `year` attribute is used to extract the current year. Finally, the current month and year are printed to the console.\n",
    "\n",
    "Please note that the current month and year will depend on the system time when you run the code.\n",
    "\n",
    "I hope this helps! Let me know if you have any further questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b09bd4-2a12-4d73-80be-7b79911fdb4b",
   "metadata": {},
   "source": [
    "Ans 8\n",
    "Certainly! Here's a Python program that takes two dates as input, calculates the difference between them in days, hours, and minutes using Pandas timedelta, and displays the result:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_time_difference():\n",
    "    # Prompt the user to enter the dates\n",
    "    date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "    date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "    # Convert the input strings to pandas datetime objects\n",
    "    date1 = pd.to_datetime(date1)\n",
    "    date2 = pd.to_datetime(date2)\n",
    "\n",
    "    # Calculate the time difference\n",
    "    time_diff = date2 - date1\n",
    "\n",
    "    # Extract the days, hours, and minutes from the time difference\n",
    "    days = time_diff.days\n",
    "    hours = time_diff.seconds // 3600\n",
    "    minutes = (time_diff.seconds // 60) % 60\n",
    "\n",
    "    # Display the result\n",
    "    print(\"Time difference: {} days, {} hours, {} minutes\".format(days, hours, minutes))\n",
    "\n",
    "# Call the function\n",
    "calculate_time_difference()\n",
    "```\n",
    "\n",
    "In this program, the `calculate_time_difference()` function prompts the user to enter two dates in the format \"YYYY-MM-DD\". The input dates are converted to pandas datetime objects using `pd.to_datetime()`.\n",
    "\n",
    "The time difference between the two dates is calculated by subtracting `date1` from `date2`, resulting in a timedelta object.\n",
    "\n",
    "The timedelta object is then used to extract the number of days (`time_diff.days`), hours (`time_diff.seconds // 3600`), and minutes (`(time_diff.seconds // 60) % 60`).\n",
    "\n",
    "Finally, the program displays the time difference in days, hours, and minutes.\n",
    "\n",
    "Note that the program assumes valid date inputs in the format \"YYYY-MM-DD\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35605b62-716e-410b-8afd-8fbf7640ee87",
   "metadata": {},
   "source": [
    "Ans 9\n",
    "Sure! Here's a Python program that reads a CSV file, converts a specified column to a categorical data type, and displays the sorted data:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path, column name, and category order\n",
    "file_path = input(\"Enter the file path: \")\n",
    "column_name = input(\"Enter the column name to convert: \")\n",
    "category_order = input(\"Enter the category order (comma-separated values): \").split(',')\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the specified column to categorical data type with the provided category order\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame based on the specified column\n",
    "sorted_df = df.sort_values(column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(sorted_df)\n",
    "```\n",
    "\n",
    "In this program, the user is prompted to enter the file path, column name, and category order. The CSV file is then read using `pd.read_csv()`, and the specified column is converted to a categorical data type using `pd.Categorical()`. The provided category order is used, and the `ordered=True` parameter is set to maintain the order of the categories.\n",
    "\n",
    "Next, the DataFrame is sorted based on the specified column using `sort_values()`, and the sorted data is stored in the `sorted_df` variable.\n",
    "\n",
    "Finally, the program displays the sorted data by printing the `sorted_df` DataFrame.\n",
    "\n",
    "Make sure to provide the correct file path, column name, and category order when prompted by the program. The program assumes that the CSV file has a header row containing column names.\n",
    "\n",
    "I hope this helps! Let me know if you have any further questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786b525-0259-4870-a9f5-5fc3f55a4db2",
   "metadata": {},
   "source": [
    "Ans 10\n",
    "Certainly! Here's a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path: \")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Set the 'Date' column as the index and convert it to datetime type\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.title('Sales by Product Category Over Time')\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this program, the user is prompted to enter the file path to the CSV file containing the sales data. The CSV file is then read using `pd.read_csv()`. The 'Date' column is set as the index of the DataFrame by converting it to datetime type and using `set_index()`.\n",
    "\n",
    "The program uses the `plot()` function from matplotlib to create a stacked bar chart (`kind='bar'`) for the DataFrame. The `stacked=True` parameter is set to stack the bars representing different product categories on top of each other. The `figsize` parameter can be adjusted to modify the size of the chart.\n",
    "\n",
    "The program sets the x-label, y-label, and title of the chart using `plt.xlabel()`, `plt.ylabel()`, and `plt.title()`, respectively.\n",
    "\n",
    "Finally, the program displays the chart using `plt.show()`.\n",
    "\n",
    "Ensure that the CSV file has a 'Date' column and columns representing different product categories with corresponding sales data.\n",
    "\n",
    "I hope this helps! Let me know if you have any further questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea348c-3a49-454f-8d6e-8f524edabe2e",
   "metadata": {},
   "source": [
    "Ans 11\n",
    "Certainly! Here's a Python program that reads a CSV file containing student data, calculates the mean, median, and mode of the test scores using Pandas, and displays the results in a table:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_statistics():\n",
    "    # Prompt the user to enter the file path of the CSV file\n",
    "    file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate the mean, median, and mode of the test scores\n",
    "    mean_score = df['Test Score'].mean()\n",
    "    median_score = df['Test Score'].median()\n",
    "    mode_scores = df['Test Score'].mode()\n",
    "\n",
    "    # Display the statistics in a table\n",
    "    statistics_table = pd.DataFrame({'Statistic': ['Mean', 'Median', 'Mode'],\n",
    "                                     'Value': [mean_score, median_score, ', '.join(map(str, mode_scores))]})\n",
    "    print(statistics_table)\n",
    "\n",
    "# Call the function\n",
    "calculate_statistics()\n",
    "```\n",
    "\n",
    "In this program, the `calculate_statistics()` function prompts the user to enter the file path of the CSV file containing the student data.\n",
    "\n",
    "The CSV file is read into a DataFrame using `pd.read_csv()`. Assuming the CSV file has columns 'Student ID' and 'Test Score', we specifically calculate the mean, median, and mode of the 'Test Score' column.\n",
    "\n",
    "The mean is calculated using the `mean()` function, the median using the `median()` function, and the mode using the `mode()` function. The mode function may return multiple values, so we use `', '.join(map(str, mode_scores))` to join the mode values as a string with comma separation.\n",
    "\n",
    "Finally, we create a new DataFrame `statistics_table` to display the statistics in a table format. The DataFrame has two columns: 'Statistic' and 'Value'. We then print the `statistics_table`.\n",
    "\n",
    "When running the program, you will be prompted to enter the file path of the CSV file. Once entered, the program calculates the mean, median, and mode of the test scores and displays the results in a table as shown in your example usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61894258-02c2-49d8-a7e2-f3a8e6f8dd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
